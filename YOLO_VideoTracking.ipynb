{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMEkyMLSIHn/VY7H3BmZbMB"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pxrjOA53kuPR"
      },
      "outputs": [],
      "source": [
        "# importação das bibliotecas\n",
        "import os\n",
        "import torch\n",
        "import utils\n",
        "from typing import Generator\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "from yolox.tracker.byte_tracker import BYTETracker, STrack\n",
        "from onemetric.cv.utils.iou import box_iou_batch\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy == 1.23"
      ],
      "metadata": {
        "id": "NEMliW_MnYdj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preparação do ambiente"
      ],
      "metadata": {
        "id": "icQH0Qgjnbpc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pasta do colab\n",
        "HOME = os.getcwd()\n",
        "print(HOME)\n",
        "\n",
        "# Clonando o repositorio\n",
        "%cd {home}\n",
        "!git clone https://github.com/ultralytics/yolov5\n",
        "%cd yolov5\n",
        "!pip install -r requirements.txt # baixando as bibliotecas necessarias\n",
        "\n",
        "display = utils.notebook_init()"
      ],
      "metadata": {
        "id": "nhYFHUxhmUp8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd {home}\n",
        "!curl 'https://drive.usercontent.google.com/download?id=1OYwrlRti4cieuvVr8ERaJhTQdFJXWT4I&export=download&confirm=t&uuid=f96e2920-f6ae-4df8-824a-5d074ed6771b&at=APZUnTX7bVRCiyoKoOprJtxtLhP6%3A1713932430806' \\\n",
        "  -H 'accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7' \\\n",
        "  -H 'accept-language: pt-BR,pt;q=0.9,en-US;q=0.8,en;q=0.7' \\\n",
        "  -H 'cookie: HSID=A8PBQYtbdcX19-LvC; SSID=Ab_7gOacd62TksF-G; APISID=0biMeZgBvDGqk1om/AlvckEcV4Z7803B_H; SAPISID=UoJugZamt_iXu17X/AYXjzxTeosURuKK1Q; __Secure-1PAPISID=UoJugZamt_iXu17X/AYXjzxTeosURuKK1Q; __Secure-3PAPISID=UoJugZamt_iXu17X/AYXjzxTeosURuKK1Q; S=billing-ui-v3=gpfs1umGOKKJg68IjjJjOBz5CXVVbi8i:billing-ui-v3-efe=gpfs1umGOKKJg68IjjJjOBz5CXVVbi8i; SID=g.a000iwj1p_o_0lCjMboSLcuZGhcAZRNocE4e3El6I2O2Wqz0xiTGBHEGTqdoW1gKApzIH_o_uAACgYKAQUSAQASFQHGX2MikbHh9nnKAgM9YcimX7S11hoVAUF8yKpY4bZ9odZZFdIpo-bOnYpr0076; __Secure-1PSID=g.a000iwj1p_o_0lCjMboSLcuZGhcAZRNocE4e3El6I2O2Wqz0xiTGnrxaCKlKtsk9g2CGPUqj-AACgYKAfUSAQASFQHGX2MijgkUQ_oEGOKSrn5gZxfmUhoVAUF8yKqsMy5v3rf1gqS4wy97kp4L0076; __Secure-3PSID=g.a000iwj1p_o_0lCjMboSLcuZGhcAZRNocE4e3El6I2O2Wqz0xiTGQuu9f_mAC_lzB-9JoNxoHAACgYKAVUSAQASFQHGX2MiWbOixSo0EKZuKWJDNNzYixoVAUF8yKocVz4SMNGdiNu25WuYTwB_0076; AEC=AQTF6HyfMyUHhBnwouPaPXtqToHlNMUHmCosuW1o3mWoIxUonPWILvHwpSs; NID=513=Yfd1cANsKKanOv0MIO1ZoYK7iEo-jP2O20OIgRlk542cLDidi8X2mkPA7n-LhngecABlEJkIFhRdu9caQQ_jeGe3X8MrFPqZogfZvKfaIcsRt2mWdP0UL53dhq-sLAbjncziAm--BI4VuwbwQYQuuaJpQ5-xaYNQ0rW9VgBEOx0pg38yRBL-KHgNxKDZxBuPI47zIjQM21BquTsivXvnS1sjAXPsaDVJVySpfF2ObcpG7o3A9tV7t71RuaOg2gxseMeccqCRbVQTD0cBHPiWgagD0T0WPvAkM88erpjAfDuM_eWPAXiQRYKxPZiqZHJxwK0LTctmbgtIr8LWAHinOl5yoSuEkKoA8gNEVwkpc_SNcA; __Secure-1PSIDTS=sidts-CjIBLwcBXAdi3cFDgw-gsPfZvajUUhBxQSVbjyeAVS_dXm21KXZcgMJTqnD9ALW-lQjf1BAA; __Secure-3PSIDTS=sidts-CjIBLwcBXAdi3cFDgw-gsPfZvajUUhBxQSVbjyeAVS_dXm21KXZcgMJTqnD9ALW-lQjf1BAA; 1P_JAR=2024-04-24-04; SIDCC=AKEyXzWUsRsnkjz-9VQzekZZxu9-qBboduLc09sPZ-KjbKRZNrTZZAzKtU0R6XMEJ-8UAO9l95BN; __Secure-1PSIDCC=AKEyXzVTybPjoaYYP-Q2VynvDHRn-frcV1OH9R7lr7atvbUlsbCvW-wnUAQAh_QuYF8VVMecFi2b; __Secure-3PSIDCC=AKEyXzXm6Ly5y3jRv_GpBaznyYijd17JXaj5A52uDajlQ3vJ-Yol7TVl8_y5YJzP9v6KGBjOB8k' \\\n",
        "  -H 'dnt: 1' \\\n",
        "  -H 'sec-ch-ua: \"Google Chrome\";v=\"123\", \"Not:A-Brand\";v=\"8\", \"Chromium\";v=\"123\"' \\\n",
        "  -H 'sec-ch-ua-arch: \"x86\"' \\\n",
        "  -H 'sec-ch-ua-bitness: \"64\"' \\\n",
        "  -H 'sec-ch-ua-full-version: \"123.0.6312.107\"' \\\n",
        "  -H 'sec-ch-ua-full-version-list: \"Google Chrome\";v=\"123.0.6312.107\", \"Not:A-Brand\";v=\"8.0.0.0\", \"Chromium\";v=\"123.0.6312.107\"' \\\n",
        "  -H 'sec-ch-ua-mobile: ?0' \\\n",
        "  -H 'sec-ch-ua-model: \"\"' \\\n",
        "  -H 'sec-ch-ua-platform: \"Windows\"' \\\n",
        "  -H 'sec-ch-ua-platform-version: \"15.0.0\"' \\\n",
        "  -H 'sec-ch-ua-wow64: ?0' \\\n",
        "  -H 'sec-fetch-dest: document' \\\n",
        "  -H 'sec-fetch-mode: navigate' \\\n",
        "  -H 'sec-fetch-site: cross-site' \\\n",
        "  -H 'sec-fetch-user: ?1' \\\n",
        "  -H 'upgrade-insecure-requests: 1' \\\n",
        "  -H 'user-agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/123.0.0.0 Safari/537.36' \\\n",
        "  -H 'x-client-data: CKq1yQEIj7bJAQiitskBCKmdygEI8tnKAQiVocsBCIWgzQEY9snNARjYhs4B' \\\n",
        "  -o 'best.pt'"
      ],
      "metadata": {
        "id": "_tVEjSxZnLHk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "WEIGHTS_PATH = f\"{home}/best.pt\""
      ],
      "metadata": {
        "id": "g7D6Ima4nQkL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Criação do modelo\n"
      ],
      "metadata": {
        "id": "BKN5I9yGnZLt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "\n",
        "def generate_frames(video_file: str) -> Generator[np.ndarray, None, None]:\n",
        "  video = cv2.VideoCapture(video_file)\n",
        "\n",
        "  while video.isOpened():\n",
        "    sucess, frame = video.read()\n",
        "\n",
        "    if not sucess:\n",
        "      break\n",
        "\n",
        "    yield frame\n",
        "\n",
        "  video.release()\n",
        "\n",
        "def plot_image(image: np.ndarray, size: int = 12) -> None:\n",
        "  plt.figure(figsize=(size, size))\n",
        "  plt.imshow(image[...,::-1])\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "9h8NHxOfn86b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importando os pesos do modelo pre treinado\n",
        "model = torch.hub.load(\"ultralytics/yolov5\",\"custom\", WEIGHTS_PATH, device = 0)"
      ],
      "metadata": {
        "id": "kN6zYTPgoyRc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# instalando o byteTrack para fazer o tracking\n",
        "%cd {HOME}\n",
        "!git clone https://github.com/ifzhang/ByteTrack.git\n",
        "!cd ByteTrack && pip3 install -r requirements.txt\n",
        "!cd ByteTrack %% python3 setup.py develop\n",
        "!pip install cython_bbox"
      ],
      "metadata": {
        "id": "z7L5PsVhpLab"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append(f\"{HOME}ByteTrack\")"
      ],
      "metadata": {
        "id": "B-qtSrMlpuRb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install onemetric --quiet"
      ],
      "metadata": {
        "id": "JfJ9XE8Jp03q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install loguru lap"
      ],
      "metadata": {
        "id": "otuaf_YCp5B7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from dataclasses import dataclass\n",
        "\n",
        "\n",
        "@dataclass(frozen=True)\n",
        "class BYTETrackerArgs:\n",
        "    track_thresh: float = 0.25\n",
        "    track_buffer: int = 30\n",
        "    match_thresh: float = 0.8\n",
        "    aspect_ratio_thresh: float = 3.0\n",
        "    min_box_area: float = 1.0\n",
        "    mot20: bool = False"
      ],
      "metadata": {
        "id": "wq1Fa-jCqvbL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Funções auxiliares"
      ],
      "metadata": {
        "id": "DXQS8CB-rJ0V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import annotations\n",
        "from dataclasses import dataclass, field\n",
        "from typing import Tuple, Optional, List, Dict, Any\n",
        "\n",
        "import cv2\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# geometry utilities\n",
        "\n",
        "\n",
        "@dataclass(frozen=True)\n",
        "class Point:\n",
        "    x: float\n",
        "    y: float\n",
        "\n",
        "    @property\n",
        "    def int_xy_tuple(self) -> Tuple[int, int]:\n",
        "        return int(self.x), int(self.y)\n",
        "\n",
        "\n",
        "@dataclass(frozen=True)\n",
        "class Rect:\n",
        "    x: float\n",
        "    y: float\n",
        "    width: float\n",
        "    height: float\n",
        "\n",
        "    @property\n",
        "    def min_x(self) -> float:\n",
        "        return self.x\n",
        "\n",
        "    @property\n",
        "    def min_y(self) -> float:\n",
        "        return self.y\n",
        "\n",
        "    @property\n",
        "    def max_x(self) -> float:\n",
        "        return self.x + self.width\n",
        "\n",
        "    @property\n",
        "    def max_y(self) -> float:\n",
        "        return self.y + self.height\n",
        "\n",
        "    @property\n",
        "    def top_left(self) -> Point:\n",
        "        return Point(x=self.x, y=self.y)\n",
        "\n",
        "    @property\n",
        "    def bottom_right(self) -> Point:\n",
        "        return Point(x=self.x + self.width, y=self.y + self.height)\n",
        "\n",
        "    @property\n",
        "    def bottom_center(self) -> Point:\n",
        "        return Point(x=self.x + self.width / 2, y=self.y + self.height)\n",
        "\n",
        "    @property\n",
        "    def top_center(self) -> Point:\n",
        "        return Point(x=self.x + self.width / 2, y=self.y)\n",
        "\n",
        "    @property\n",
        "    def center(self) -> Point:\n",
        "        return Point(x=self.x + self.width / 2, y=self.y + self.height / 2)\n",
        "\n",
        "    def pad(self, padding: float) -> Rect:\n",
        "        return Rect(\n",
        "            x=self.x - padding,\n",
        "            y=self.y - padding,\n",
        "            width=self.width + 2*padding,\n",
        "            height=self.height + 2*padding\n",
        "        )\n",
        "\n",
        "    def contains_point(self, point: Point) -> bool:\n",
        "        return self.min_x < point.x < self.max_x and self.min_y < point.y < self.max_y\n",
        "\n",
        "\n",
        "# detection utilities\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class Detection:\n",
        "    rect: Rect\n",
        "    class_id: int\n",
        "    class_name: str\n",
        "    confidence: float\n",
        "    tracker_id: Optional[int] = None\n",
        "\n",
        "    @classmethod\n",
        "    def from_results(cls, pred: np.ndarray, names: Dict[int, str]) -> List[Detection]:\n",
        "        result = []\n",
        "        for x_min, y_min, x_max, y_max, confidence, class_id in pred:\n",
        "            class_id=int(class_id)\n",
        "            result.append(Detection(\n",
        "                rect=Rect(\n",
        "                    x=float(x_min),\n",
        "                    y=float(y_min),\n",
        "                    width=float(x_max - x_min),\n",
        "                    height=float(y_max - y_min)\n",
        "                ),\n",
        "                class_id=class_id,\n",
        "                class_name=names[class_id],\n",
        "                confidence=float(confidence)\n",
        "            ))\n",
        "        return result\n",
        "\n",
        "\n",
        "def filter_detections_by_class(detections: List[Detection], class_name: str) -> List[Detection]:\n",
        "    return [\n",
        "        detection\n",
        "        for detection\n",
        "        in detections\n",
        "        if detection.class_name == class_name\n",
        "    ]\n",
        "\n",
        "\n",
        "# draw utilities\n",
        "\n",
        "\n",
        "@dataclass(frozen=True)\n",
        "class Color:\n",
        "    r: int\n",
        "    g: int\n",
        "    b: int\n",
        "\n",
        "    @property\n",
        "    def bgr_tuple(self) -> Tuple[int, int, int]:\n",
        "        return self.b, self.g, self.r\n",
        "\n",
        "    @classmethod\n",
        "    def from_hex_string(cls, hex_string: str) -> Color:\n",
        "        r, g, b = tuple(int(hex_string[1 + i:1 + i + 2], 16) for i in (0, 2, 4))\n",
        "        return Color(r=r, g=g, b=b)\n",
        "\n",
        "\n",
        "def draw_rect(image: np.ndarray, rect: Rect, color: Color, thickness: int = 2) -> np.ndarray:\n",
        "    cv2.rectangle(image, rect.top_left.int_xy_tuple, rect.bottom_right.int_xy_tuple, color.bgr_tuple, thickness)\n",
        "    return image\n",
        "\n",
        "\n",
        "def draw_filled_rect(image: np.ndarray, rect: Rect, color: Color) -> np.ndarray:\n",
        "    cv2.rectangle(image, rect.top_left.int_xy_tuple, rect.bottom_right.int_xy_tuple, color.bgr_tuple, -1)\n",
        "    return image\n",
        "\n",
        "\n",
        "def draw_polygon(image: np.ndarray, countour: np.ndarray, color: Color, thickness: int = 2) -> np.ndarray:\n",
        "    cv2.drawContours(image, [countour], 0, color.bgr_tuple, thickness)\n",
        "    return image\n",
        "\n",
        "\n",
        "def draw_filled_polygon(image: np.ndarray, countour: np.ndarray, color: Color) -> np.ndarray:\n",
        "    cv2.drawContours(image, [countour], 0, color.bgr_tuple, -1)\n",
        "    return image\n",
        "\n",
        "\n",
        "def draw_text(image: np.ndarray, anchor: Point, text: str, color: Color, thickness: int = 2) -> np.ndarray:\n",
        "    cv2.putText(image, text, anchor.int_xy_tuple, cv2.FONT_HERSHEY_SIMPLEX, 0.7, color.bgr_tuple, thickness, 2, False)\n",
        "    return image\n",
        "\n",
        "\n",
        "def draw_ellipse(image: np.ndarray, rect: Rect, color: Color, thickness: int = 2) -> np.ndarray:\n",
        "    cv2.ellipse(\n",
        "        image,\n",
        "        center=rect.bottom_center.int_xy_tuple,\n",
        "        axes=(int(rect.width), int(0.35 * rect.width)),\n",
        "        angle=0.0,\n",
        "        startAngle=-45,\n",
        "        endAngle=235,\n",
        "        color=color.bgr_tuple,\n",
        "        thickness=thickness,\n",
        "        lineType=cv2.LINE_4\n",
        "    )\n",
        "    return image\n",
        "\n",
        "\n",
        "# base annotator\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class BaseAnnotator:\n",
        "    colors: List[Color]\n",
        "    thickness: int\n",
        "\n",
        "    def annotate(self, image: np.ndarray, detections: List[Detection]) -> np.ndarray:\n",
        "        annotated_image = image.copy()\n",
        "        for detection in detections:\n",
        "            annotated_image = draw_ellipse(\n",
        "                image=image,\n",
        "                rect=detection.rect,\n",
        "                color=self.colors[detection.class_id],\n",
        "                thickness=self.thickness\n",
        "            )\n",
        "        return annotated_image\n",
        "\n",
        "\n",
        "\n",
        "# white\n",
        "BALL_COLOR_HEX = \"#FFFFFF\"\n",
        "BALL_COLOR = Color.from_hex_string(BALL_COLOR_HEX)\n",
        "\n",
        "# red\n",
        "GOALKEEPER_COLOR_HEX = \"#850101\"\n",
        "GOALKEEPER_COLOR = Color.from_hex_string(GOALKEEPER_COLOR_HEX)\n",
        "\n",
        "# green\n",
        "PLAYER_COLOR_HEX = \"#00D4BB\"\n",
        "PLAYER_COLOR = Color.from_hex_string(PLAYER_COLOR_HEX)\n",
        "\n",
        "# yellow\n",
        "REFEREE_COLOR_HEX = \"#FFFF00\"\n",
        "REFEREE_COLOR = Color.from_hex_string(REFEREE_COLOR_HEX)\n",
        "\n",
        "COLORS = [\n",
        "    BALL_COLOR,\n",
        "    GOALKEEPER_COLOR,\n",
        "    PLAYER_COLOR,\n",
        "    REFEREE_COLOR\n",
        "]\n",
        "THICKNESS = 4\n",
        "# black\n",
        "MARKER_CONTOUR_COLOR_HEX = \"000000\"\n",
        "MARKER_CONTOUR_COLOR = Color.from_hex_string(MARKER_CONTOUR_COLOR_HEX)\n",
        "\n",
        "# red\n",
        "PLAYER_MARKER_FILL_COLOR_HEX = \"FF0000\"\n",
        "PLAYER_MARKER_FILL_COLOR = Color.from_hex_string(PLAYER_MARKER_FILL_COLOR_HEX)\n",
        "\n",
        "# green\n",
        "BALL_MERKER_FILL_COLOR_HEX = \"00FF00\"\n",
        "BALL_MARKER_FILL_COLOR = Color.from_hex_string(BALL_MERKER_FILL_COLOR_HEX)\n",
        "\n",
        "MARKER_CONTOUR_THICKNESS = 2\n",
        "MARKER_WIDTH = 20\n",
        "MARKER_HEIGHT = 20\n",
        "MARKER_MARGIN = 10\n",
        "\n",
        "# distance in pixels from the player's bounding box where we consider the ball is in his possession\n",
        "PLAYER_IN_POSSESSION_PROXIMITY = 30\n",
        "\n",
        "from typing import List\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "\"\"\"\n",
        "BYTETracker does not assign tracker_id to existing bounding boxes but rather\n",
        "predicts the next bounding box position based on previous one. Therefore, we\n",
        "need to find a way to match our bounding boxes with predictions.\n",
        "\n",
        "usage example:\n",
        "\n",
        "byte_tracker = BYTETracker(BYTETrackerArgs())\n",
        "for frame in frames:\n",
        "    ...\n",
        "    results = model(frame, size=1280)\n",
        "    detections = Detection.from_results(\n",
        "        pred=results.pred[0].cpu().numpy(),\n",
        "        names=model.names)\n",
        "    ...\n",
        "    tracks = byte_tracker.update(\n",
        "        output_results=detections2boxes(detections=detections),\n",
        "        img_info=frame.shape,\n",
        "        img_size=frame.shape)\n",
        "    detections = match_detections_with_tracks(detections=detections, tracks=tracks)\n",
        "\"\"\"\n",
        "\n",
        "# converts List[Detection] into format that can be consumed by match_detections_with_tracks function\n",
        "def detections2boxes(detections: List[Detection], with_confidence: bool = True) -> np.ndarray:\n",
        "    return np.array([\n",
        "        [\n",
        "            detection.rect.top_left.x,\n",
        "            detection.rect.top_left.y,\n",
        "            detection.rect.bottom_right.x,\n",
        "            detection.rect.bottom_right.y,\n",
        "            detection.confidence\n",
        "        ] if with_confidence else [\n",
        "            detection.rect.top_left.x,\n",
        "            detection.rect.top_left.y,\n",
        "            detection.rect.bottom_right.x,\n",
        "            detection.rect.bottom_right.y\n",
        "        ]\n",
        "        for detection\n",
        "        in detections\n",
        "    ], dtype=float)\n",
        "\n",
        "\n",
        "# converts List[STrack] into format that can be consumed by match_detections_with_tracks function\n",
        "def tracks2boxes(tracks: List[STrack]) -> np.ndarray:\n",
        "    return np.array([\n",
        "        track.tlbr\n",
        "        for track\n",
        "        in tracks\n",
        "    ], dtype=float)\n",
        "\n",
        "\n",
        "# matches our bounding boxes with predictions\n",
        "def match_detections_with_tracks(\n",
        "    detections: List[Detection],\n",
        "    tracks: List[STrack]\n",
        ") -> List[Detection]:\n",
        "    detection_boxes = detections2boxes(detections=detections, with_confidence=False)\n",
        "    tracks_boxes = tracks2boxes(tracks=tracks)\n",
        "    iou = box_iou_batch(tracks_boxes, detection_boxes)\n",
        "    track2detection = np.argmax(iou, axis=1)\n",
        "\n",
        "    for tracker_index, detection_index in enumerate(track2detection):\n",
        "        if iou[tracker_index, detection_index] != 0:\n",
        "            detections[detection_index].tracker_id = tracks[tracker_index].track_id\n",
        "    return detections\n",
        "\n",
        "\n",
        "from dataclasses import dataclass\n",
        "import cv2\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "usage example:\n",
        "\n",
        "video_config = VideoConfig(\n",
        "    fps=30,\n",
        "    width=1920,\n",
        "    height=1080)\n",
        "video_writer = get_video_writer(\n",
        "    target_video_path=TARGET_VIDEO_PATH,\n",
        "    video_config=video_config)\n",
        "\n",
        "for frame in frames:\n",
        "    ...\n",
        "    video_writer.write(frame)\n",
        "\n",
        "video_writer.release()\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "# stores information about output video file, width and height of the frame must be equal to input video\n",
        "@dataclass(frozen=True)\n",
        "class VideoConfig:\n",
        "    fps: float\n",
        "    width: int\n",
        "    height: int\n",
        "\n",
        "\n",
        "# create cv2.VideoWriter object that we can use to save output video\n",
        "def get_video_writer(target_video_path: str, video_config: VideoConfig) -> cv2.VideoWriter:\n",
        "    video_target_dir = os.path.dirname(os.path.abspath(target_video_path))\n",
        "    os.makedirs(video_target_dir, exist_ok=True)\n",
        "    return cv2.VideoWriter(\n",
        "        target_video_path,\n",
        "        fourcc=cv2.VideoWriter_fourcc(*\"mp4v\"),\n",
        "        fps=video_config.fps,\n",
        "        frameSize=(video_config.width, video_config.height),\n",
        "        isColor=True\n",
        "    )\n",
        "\n",
        "\n",
        "from typing import List, Optional\n",
        "\n",
        "\n",
        "# resolves which player is currently in ball possession based on player-ball proximity\n",
        "def get_player_in_possession(\n",
        "    player_detections: List[Detection],\n",
        "    ball_detections: List[Detection],\n",
        "    proximity: int\n",
        ") -> Optional[Detection]:\n",
        "    if len(ball_detections) != 1:\n",
        "        return None\n",
        "    ball_detection = ball_detections[0]\n",
        "    for player_detection in player_detections:\n",
        "        if player_detection.rect.pad(proximity).contains_point(point=ball_detection.rect.center):\n",
        "            return player_detection\n",
        "\n",
        "\n",
        "from typing import List\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# calculates coordinates of possession marker\n",
        "def calculate_marker(anchor: Point) -> np.ndarray:\n",
        "    x, y = anchor.int_xy_tuple\n",
        "    return(np.array([\n",
        "        [x - MARKER_WIDTH // 2, y - MARKER_HEIGHT - MARKER_MARGIN],\n",
        "        [x, y - MARKER_MARGIN],\n",
        "        [x + MARKER_WIDTH // 2, y - MARKER_HEIGHT - MARKER_MARGIN]\n",
        "    ]))\n",
        "\n",
        "\n",
        "# draw single possession marker\n",
        "def draw_marker(image: np.ndarray, anchor: Point, color: Color) -> np.ndarray:\n",
        "    possession_marker_countour = calculate_marker(anchor=anchor)\n",
        "    image = draw_filled_polygon(\n",
        "        image=image,\n",
        "        countour=possession_marker_countour,\n",
        "        color=color)\n",
        "    image = draw_polygon(\n",
        "        image=image,\n",
        "        countour=possession_marker_countour,\n",
        "        color=MARKER_CONTOUR_COLOR,\n",
        "        thickness=MARKER_CONTOUR_THICKNESS)\n",
        "    return image\n",
        "\n",
        "\n",
        "# dedicated annotator to draw possession markers on video frames\n",
        "@dataclass\n",
        "class MarkerAnntator:\n",
        "\n",
        "    color: Color\n",
        "\n",
        "    def annotate(self, image: np.ndarray, detections: List[Detection]) -> np.ndarray:\n",
        "        annotated_image = image.copy()\n",
        "        for detection in detections:\n",
        "            annotated_image = draw_marker(\n",
        "                image=image,\n",
        "                anchor=detection.rect.top_center,\n",
        "                color=self.color)\n",
        "        return annotated_image\n",
        "\n",
        "# text annotator to display tracker_id\n",
        "@dataclass\n",
        "class TextAnnotator:\n",
        "    background_color: Color\n",
        "    text_color: Color\n",
        "    text_thickness: int\n",
        "\n",
        "    def annotate(self, image: np.ndarray, detections: List[Detection]) -> np.ndarray:\n",
        "        annotated_image = image.copy()\n",
        "        for detection in detections:\n",
        "            # if tracker_id is not assigned skip annotation\n",
        "            if detection.tracker_id is None:\n",
        "                continue\n",
        "\n",
        "            # calculate text dimensions\n",
        "            size, _ = cv2.getTextSize(\n",
        "                str(detection.tracker_id),\n",
        "                cv2.FONT_HERSHEY_SIMPLEX,\n",
        "                0.7,\n",
        "                thickness=self.text_thickness)\n",
        "            width, height = size\n",
        "\n",
        "            # calculate text background position\n",
        "            center_x, center_y = detection.rect.bottom_center.int_xy_tuple\n",
        "            x = center_x - width // 2\n",
        "            y = center_y - height // 2 + 10\n",
        "\n",
        "            # draw background\n",
        "            annotated_image = draw_filled_rect(\n",
        "                image=annotated_image,\n",
        "                rect=Rect(x=x, y=y, width=width, height=height).pad(padding=5),\n",
        "                color=self.background_color)\n",
        "\n",
        "            # draw text\n",
        "            annotated_image = draw_text(\n",
        "                image=annotated_image,\n",
        "                anchor=Point(x=x, y=y + height),\n",
        "                text=str(detection.tracker_id),\n",
        "                color=self.text_color,\n",
        "                thickness=self.text_thickness)\n",
        "        return annotated_image"
      ],
      "metadata": {
        "id": "7hCd2yvNqxqb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SOURCE_VIDEO_PATH = f\"{HOME}/clips/video.mp4\"\n",
        "TARGET_VIDEO_PATH = f\"{HOME}/final/novovideo.mp4\""
      ],
      "metadata": {
        "id": "woXiE6birMJz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}