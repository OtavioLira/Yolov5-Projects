{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vmo2w561bqNe"
      },
      "source": [
        "> FIAP - Faculdade de InformÃ¡tica e AdministraÃ§Ã£o Paulista\n",
        "\n",
        "# Global Solutions 2023 - AI Challenges and Solutions\n",
        "\n",
        "Detector de alimentos usando YOLOv5 e ESP32-CAM\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QRED7OuYbqNg"
      },
      "source": [
        "## CriaÃ§Ã£o do banco de imagens de alimentos\n",
        "\n",
        "Para treinar o nosso detector, precisamos de um bom nÃºmero de exemplos de imagens dos alimentos que queremos detectar, para isso, vamos usar imagens da internet contendo o nosso alimento. A ideia Ã© ter o mÃ¡ximo de tipos de fotos de diversos Ã¢ngulos do nosso alimento.\n",
        "\n",
        "Quanto mais exemplos e situaÃ§Ãµes temos do nosso alimento (Ambiente escuro, Ã¢ngulos, fases de maturaÃ§Ã£o, etc.) melhor nosso modelo vai detectar. Por exemplo, se tivemos apenas exemplos de fotos de perfil de um alimento, ele provavelmente sÃ³ irÃ¡ conseguir detectar um alimento se colocarmos ele de perfil e com uma iluminaÃ§Ã£o focada no alimento.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K6pKiIRzbqNh"
      },
      "source": [
        "### Busca de fotos\n",
        "\n",
        "- Procure imagens contendo o alimento e salve tudo em uma pasta local.\n",
        "  - Se possÃ­vel, renomeie cada arquivo nesse formato: `[NOME DO ALIMENTO]_[NUMERO DO EXEMPLO]` (Opcional)\n",
        "  - Exemplo: `maca_01`. Isso vai facilitar na visualizaÃ§Ã£o e organizaÃ§Ã£o dos arquivos.\n",
        "- ApÃ³s isso, separe 80% em uma nova pasta chamada `train` e o resto em uma pasta chamada `val`\n",
        "- Mova as pastas `train` e `val` para uma nova pastas chamada `images`\n",
        "\n",
        "### CriaÃ§Ã£o dos labels\n",
        "\n",
        "Agora que temos as imagens separadas, vamos criar os rÃ³tulos de cada alimento, para isso, temos que delimitar onde cada alimento estÃ¡ em cada imagem de treino e validaÃ§Ã£o.\n",
        "\n",
        "Vamos usar o site [makesense.ai](https://makesense.ai) para isso.\n",
        "\n",
        "- Entre no site e clique em \"Get started\"\n",
        "- Arraste a pasta de imagens de treino/validacao para o quadrado das imagens. (VocÃª irÃ¡ precisar fazer esse processo com as duas, uma de cada vez)\n",
        "- Clique em \"Object Detection\"\n",
        "- No modal de \"Create Labels\" crie um rÃ³tulo para cada tipo de alimento que vocÃª irÃ¡ rotular.\n",
        "- Clique em \"Start project\"\n",
        "- Crie uma caixa delimitadora retangular para cada alimento em cada imagem. Exemplo:\n",
        "  ![Exemplo label de uma maÃ§Ã£](docs/readme/label.png)\n",
        "  > Importante! Se houver mais de um alimento na foto, crie uma caixa para cada alimento, mesmo que eles sejam do mesmo tipo. Exemplo: Se houver duas maÃ§Ã£s na foto, crie uma caixa para cada maÃ§Ã£, e nÃ£o uma caixa sÃ³ para as duas junto.\n",
        "- ApÃ³s criar as caixas para todas as imagens, vÃ¡ em \"Actions\" e \"Export annotations\".\n",
        "- Dentro do modal, selecione \"A .zip package containing files in YOLO format\". Dentro desse zip estÃ£o todos os rÃ³tulos para cada imagem.\n",
        "- Crie uma pasta chamada `labels` e dentro dela crie uma nova pasta com o tipo de imagem que vocÃª estava rotulando (`train` ou `val`).\n",
        "- Extraia o conteÃºdo do .zip para a pasta que vocÃª criou.\n",
        "- Repita o processo com as imagens de validaÃ§Ã£o/treino. No final, vocÃª terÃ¡ que ter os labels de treino e validaÃ§Ã£o dentro da sua respectiva pasta.\n",
        "\n",
        "No final do processo, vocÃª terÃ¡ que ter essa estrutura de arquivos:\n",
        "\n",
        "```text\n",
        "- images/\n",
        "  - train/\n",
        "    - imagens de treino\n",
        "  - val/\n",
        "    - imagens de validaÃ§Ã£o\n",
        "- labels/\n",
        "  - train/\n",
        "    - labels das imagens de treino\n",
        "  - val/\n",
        "    - labels das imagens de validaÃ§Ã£o\n",
        "```\n",
        "\n",
        "**Pronto! Agora vamos para o treinamento do nosso modelo**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RAvuH9fbbqNi"
      },
      "source": [
        "## Treinando o modelo\n",
        "\n",
        "### Configurando o YOLO\n",
        "\n",
        "Primeiro, faÃ§a o clone ou baixe como zip e extraia o repositÃ³rio oficial do YOLOv5:\n",
        "\n",
        "- [Download como zip](https://github.com/ultralytics/yolov5/archive/refs/heads/master.zip)\n",
        "- Ou rode execute o cÃ³digo abaixo:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I2ZfzKA7bqNi",
        "outputId": "6a1bfe3d-3018-45ee-81ae-4e5ae1b1ecad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'yolov5'...\n",
            "remote: Enumerating objects: 16008, done.\u001b[K\n",
            "remote: Counting objects: 100% (41/41), done.\u001b[K\n",
            "remote: Compressing objects: 100% (28/28), done.\u001b[K\n",
            "remote: Total 16008 (delta 22), reused 21 (delta 13), pack-reused 15967\u001b[K\n",
            "Receiving objects: 100% (16008/16008), 14.60 MiB | 19.19 MiB/s, done.\n",
            "Resolving deltas: 100% (10988/10988), done.\n"
          ]
        }
      ],
      "source": [
        "! git clone https://github.com/ultralytics/yolov5.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DSUTZKzrbqNk"
      },
      "source": [
        "Com o cÃ³digo do YOLO no seu computador, baixe as dependÃªncias necessÃ¡rias para fazer ele rodar:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WIved_gNbqNl",
        "outputId": "78afbf87-edc7-4c68-82da-24a5b54703f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gitpython>=3.1.30 (from -r yolov5/requirements.txt (line 5))\n",
            "  Downloading GitPython-3.1.38-py3-none-any.whl (190 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m190.6/190.6 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib>=3.3 in /usr/local/lib/python3.10/dist-packages (from -r yolov5/requirements.txt (line 6)) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.22.2 in /usr/local/lib/python3.10/dist-packages (from -r yolov5/requirements.txt (line 7)) (1.23.5)\n",
            "Requirement already satisfied: opencv-python>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from -r yolov5/requirements.txt (line 8)) (4.8.0.76)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from -r yolov5/requirements.txt (line 9)) (9.4.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from -r yolov5/requirements.txt (line 10)) (5.9.5)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from -r yolov5/requirements.txt (line 11)) (6.0.1)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from -r yolov5/requirements.txt (line 12)) (2.31.0)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from -r yolov5/requirements.txt (line 13)) (1.11.3)\n",
            "Collecting thop>=0.1.1 (from -r yolov5/requirements.txt (line 14))\n",
            "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from -r yolov5/requirements.txt (line 15)) (2.0.1+cu118)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from -r yolov5/requirements.txt (line 16)) (0.15.2+cu118)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from -r yolov5/requirements.txt (line 17)) (4.66.1)\n",
            "Collecting ultralytics>=8.0.147 (from -r yolov5/requirements.txt (line 18))\n",
            "  Downloading ultralytics-8.0.199-py3-none-any.whl (644 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m644.5/644.5 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from -r yolov5/requirements.txt (line 27)) (1.5.3)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from -r yolov5/requirements.txt (line 28)) (0.12.2)\n",
            "Requirement already satisfied: setuptools>=65.5.1 in /usr/local/lib/python3.10/dist-packages (from -r yolov5/requirements.txt (line 42)) (67.7.2)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython>=3.1.30->-r yolov5/requirements.txt (line 5))\n",
            "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r yolov5/requirements.txt (line 6)) (1.1.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r yolov5/requirements.txt (line 6)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r yolov5/requirements.txt (line 6)) (4.43.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r yolov5/requirements.txt (line 6)) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r yolov5/requirements.txt (line 6)) (23.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r yolov5/requirements.txt (line 6)) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r yolov5/requirements.txt (line 6)) (2.8.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r yolov5/requirements.txt (line 12)) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r yolov5/requirements.txt (line 12)) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r yolov5/requirements.txt (line 12)) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r yolov5/requirements.txt (line 12)) (2023.7.22)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r yolov5/requirements.txt (line 15)) (3.12.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r yolov5/requirements.txt (line 15)) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r yolov5/requirements.txt (line 15)) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r yolov5/requirements.txt (line 15)) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r yolov5/requirements.txt (line 15)) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r yolov5/requirements.txt (line 15)) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.8.0->-r yolov5/requirements.txt (line 15)) (3.27.6)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.8.0->-r yolov5/requirements.txt (line 15)) (17.0.2)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics>=8.0.147->-r yolov5/requirements.txt (line 18)) (9.0.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->-r yolov5/requirements.txt (line 27)) (2023.3.post1)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython>=3.1.30->-r yolov5/requirements.txt (line 5))\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3->-r yolov5/requirements.txt (line 6)) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->-r yolov5/requirements.txt (line 15)) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->-r yolov5/requirements.txt (line 15)) (1.3.0)\n",
            "Installing collected packages: smmap, gitdb, gitpython, thop, ultralytics\n",
            "Successfully installed gitdb-4.0.10 gitpython-3.1.38 smmap-5.0.1 thop-0.1.1.post2209072238 ultralytics-8.0.199\n"
          ]
        }
      ],
      "source": [
        "! pip install -r yolov5/requirements.txt  # install"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "31VQidacdaoL",
        "outputId": "f89835ca-0499-47b7-8709-47add051e657"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CVWiuJhzbqNl"
      },
      "source": [
        "Crie um arquivo de configuraÃ§Ã£o para o dataset chamado `alimentos.yaml`, contendo o seguinte cÃ³digo:\n",
        "\n",
        "```yaml\n",
        "train: ../../images/train/ # NÃƒO EDITAR\n",
        "val: ../../images/val/ # NÃƒO EDITAR\n",
        "\n",
        "names: # Defina aqui as labels do seu dataset\n",
        "  0: \"MaÃ§Ã£\"\n",
        "  1: \"Banana\"\n",
        "  2: \"Laranja\"\n",
        "  # ...\n",
        "```\n",
        "\n",
        "As labels tem que estar na mesma ordem que vocÃª criou no makesense.ai\n",
        "\n",
        "Com o arquivo de configuraÃ§Ã£o criado, podemos treinar o modelo.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KUA-V44zbqNl"
      },
      "source": [
        "### Treinando o modelo\n",
        "\n",
        "Rode o cÃ³digo abaixo para treinar o modelo:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZXU4E32SbqNl",
        "outputId": "9e75acdf-55ac-442e-a0b9-3c765df82aeb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5l.pt, cfg=, data=trator.yaml, hyp=yolov5/data/hyps/hyp.scratch-low.yaml, epochs=40, batch_size=16, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=yolov5/runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 âœ…\n",
            "YOLOv5 ðŸš€ v7.0-227-ge4df1ec Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 ðŸš€ runs in Comet\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir yolov5/runs/train', view at http://localhost:6006/\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to /root/.config/Ultralytics/Arial.ttf...\n",
            "100% 755k/755k [00:00<00:00, 20.4MB/s]\n",
            "Downloading https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5l.pt to yolov5l.pt...\n",
            "100% 89.3M/89.3M [00:01<00:00, 67.8MB/s]\n",
            "\n",
            "Overriding model.yaml nc=80 with nc=1\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      7040  models.common.Conv                      [3, 64, 6, 2, 2]              \n",
            "  1                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  2                -1  3    156928  models.common.C3                        [128, 128, 3]                 \n",
            "  3                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  4                -1  6   1118208  models.common.C3                        [256, 256, 6]                 \n",
            "  5                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  6                -1  9   6433792  models.common.C3                        [512, 512, 9]                 \n",
            "  7                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 2]             \n",
            "  8                -1  3   9971712  models.common.C3                        [1024, 1024, 3]               \n",
            "  9                -1  1   2624512  models.common.SPPF                      [1024, 1024, 5]               \n",
            " 10                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  3   2757632  models.common.C3                        [1024, 512, 3, False]         \n",
            " 14                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  3    690688  models.common.C3                        [512, 256, 3, False]          \n",
            " 18                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  3   2495488  models.common.C3                        [512, 512, 3, False]          \n",
            " 21                -1  1   2360320  models.common.Conv                      [512, 512, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  3   9971712  models.common.C3                        [1024, 1024, 3, False]        \n",
            " 24      [17, 20, 23]  1     32310  models.yolo.Detect                      [1, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [256, 512, 1024]]\n",
            "Model summary: 368 layers, 46138294 parameters, 46138294 gradients, 108.2 GFLOPs\n",
            "\n",
            "Transferred 607/613 items from yolov5l.pt\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 101 weight(decay=0.0), 104 weight(decay=0.0005), 104 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/1TIAF/Drone/labels/train... 9 images, 12 backgrounds, 0 corrupt: 100% 21/21 [00:12<00:00,  1.64it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/drive/MyDrive/1TIAF/Drone/images/train/Image_8.jpeg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/drive/MyDrive/1TIAF/Drone/labels/train.cache\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/1TIAF/Drone/labels/val... 3 images, 0 backgrounds, 0 corrupt: 100% 3/3 [00:02<00:00,  1.14it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/drive/MyDrive/1TIAF/Drone/labels/val.cache\n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m2.10 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset âœ…\n",
            "Plotting labels to yolov5/runs/train/exp2/labels.jpg... \n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1myolov5/runs/train/exp2\u001b[0m\n",
            "Starting training for 40 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       0/39      9.57G    0.07332    0.02651          0          9        640: 100% 2/2 [00:06<00:00,  3.05s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:01<00:00,  1.68s/it]\n",
            "                   all          3          3          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       1/39      9.57G    0.07333      0.025          0          5        640: 100% 2/2 [00:01<00:00,  1.58it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  2.16it/s]\n",
            "                   all          3          3          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       2/39      9.57G    0.06452     0.0256          0          6        640: 100% 2/2 [00:00<00:00,  2.21it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  4.14it/s]\n",
            "                   all          3          3          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       3/39      9.57G    0.07149    0.02457          0          7        640: 100% 2/2 [00:00<00:00,  2.19it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  3.53it/s]\n",
            "                   all          3          3          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       4/39      9.57G    0.06231    0.02422          0          4        640: 100% 2/2 [00:00<00:00,  2.24it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  3.79it/s]\n",
            "                   all          3          3    0.00111      0.333    0.00105   0.000315\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       5/39      9.57G    0.05676    0.02281          0          4        640: 100% 2/2 [00:01<00:00,  1.88it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  2.14it/s]\n",
            "                   all          3          3    0.00222      0.667    0.00505    0.00106\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       6/39      9.57G     0.0642     0.0248          0          7        640: 100% 2/2 [00:00<00:00,  2.38it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  3.92it/s]\n",
            "                   all          3          3    0.00333          1      0.016    0.00402\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       7/39      9.57G    0.04394     0.0236          0          6        640: 100% 2/2 [00:00<00:00,  2.19it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  3.62it/s]\n",
            "                   all          3          3    0.00333          1     0.0885     0.0115\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       8/39      9.57G    0.05518    0.02639          0         10        640: 100% 2/2 [00:00<00:00,  2.40it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  4.23it/s]\n",
            "                   all          3          3    0.00333          1      0.181     0.0349\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       9/39      9.58G    0.04653    0.02408          0          5        640: 100% 2/2 [00:00<00:00,  2.31it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  4.74it/s]\n",
            "                   all          3          3    0.00333          1      0.209     0.0771\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      10/39      9.58G    0.04941    0.02587          0          8        640: 100% 2/2 [00:00<00:00,  2.35it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  4.78it/s]\n",
            "                   all          3          3    0.00333          1      0.456     0.0843\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      11/39      9.58G    0.04968    0.02621          0          9        640: 100% 2/2 [00:00<00:00,  2.19it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  2.40it/s]\n",
            "                   all          3          3    0.00333          1      0.373     0.0804\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      12/39      9.58G    0.05544    0.02253          0          5        640: 100% 2/2 [00:00<00:00,  2.06it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  3.65it/s]\n",
            "                   all          3          3    0.00333          1      0.399      0.183\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      13/39      9.58G    0.07127    0.02296          0          5        640: 100% 2/2 [00:00<00:00,  2.38it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  5.11it/s]\n",
            "                   all          3          3    0.00333          1       0.45      0.276\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      14/39      9.58G    0.04183     0.0272          0         10        640: 100% 2/2 [00:00<00:00,  2.40it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  4.94it/s]\n",
            "                   all          3          3    0.00333          1      0.641      0.292\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      15/39      9.58G    0.04386    0.01858          0          4        640: 100% 2/2 [00:00<00:00,  2.42it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  4.34it/s]\n",
            "                   all          3          3    0.00333          1      0.597      0.217\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      16/39      9.58G    0.04223    0.02198          0          7        640: 100% 2/2 [00:00<00:00,  2.28it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  5.26it/s]\n",
            "                   all          3          3    0.00333          1      0.324      0.173\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      17/39      9.58G    0.03847    0.02236          0          8        640: 100% 2/2 [00:00<00:00,  2.08it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  3.21it/s]\n",
            "                   all          3          3    0.00333          1      0.731       0.44\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      18/39      9.58G    0.04356    0.02177          0          5        640: 100% 2/2 [00:00<00:00,  2.34it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  5.71it/s]\n",
            "                   all          3          3    0.00492          1      0.995      0.631\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      19/39      9.58G    0.03432    0.02468          0         10        640: 100% 2/2 [00:01<00:00,  1.94it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  2.33it/s]\n",
            "                   all          3          3     0.0144          1      0.995      0.697\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      20/39      9.58G    0.06433    0.01684          0          2        640: 100% 2/2 [00:00<00:00,  2.35it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  4.01it/s]\n",
            "                   all          3          3     0.0444          1      0.995       0.64\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      21/39      9.58G    0.04352    0.02014          0          8        640: 100% 2/2 [00:00<00:00,  2.29it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  6.03it/s]\n",
            "                   all          3          3      0.152          1      0.995      0.531\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      22/39      9.58G    0.03869    0.02018          0          7        640: 100% 2/2 [00:00<00:00,  2.13it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  6.33it/s]\n",
            "                   all          3          3      0.254          1      0.995      0.624\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      23/39      9.58G    0.02965    0.01833          0          3        640: 100% 2/2 [00:00<00:00,  2.40it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  6.12it/s]\n",
            "                   all          3          3      0.378          1      0.995       0.68\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      24/39      9.58G    0.02832    0.01663          0          3        640: 100% 2/2 [00:00<00:00,  2.31it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  5.73it/s]\n",
            "                   all          3          3      0.477          1      0.995       0.68\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      25/39      9.58G    0.04045    0.01726          0          7        640: 100% 2/2 [00:00<00:00,  2.15it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  3.92it/s]\n",
            "                   all          3          3      0.647          1      0.995      0.631\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      26/39      9.58G    0.03914    0.01784          0          7        640: 100% 2/2 [00:00<00:00,  2.31it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  6.47it/s]\n",
            "                   all          3          3      0.811          1      0.995      0.614\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      27/39      9.58G     0.0351    0.02354          0         10        640: 100% 2/2 [00:00<00:00,  2.40it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  7.37it/s]\n",
            "                   all          3          3      0.811          1      0.995      0.614\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      28/39      9.58G    0.03753    0.02245          0         10        640: 100% 2/2 [00:01<00:00,  1.96it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  3.75it/s]\n",
            "                   all          3          3      0.829          1      0.995      0.614\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      29/39      9.58G    0.06339    0.01843          0          6        640: 100% 2/2 [00:00<00:00,  2.14it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  7.20it/s]\n",
            "                   all          3          3      0.848          1      0.995      0.614\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      30/39      9.58G    0.03227    0.01774          0          4        640: 100% 2/2 [00:00<00:00,  2.44it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  5.76it/s]\n",
            "                   all          3          3      0.848          1      0.995      0.614\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      31/39      9.58G    0.03872    0.01814          0          8        640: 100% 2/2 [00:00<00:00,  2.06it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  3.86it/s]\n",
            "                   all          3          3      0.908          1      0.995      0.614\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      32/39      9.58G    0.02406    0.01536          0          4        640: 100% 2/2 [00:00<00:00,  2.20it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  7.46it/s]\n",
            "                   all          3          3      0.753          1      0.995      0.641\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      33/39      9.58G    0.03152    0.01614          0          5        640: 100% 2/2 [00:00<00:00,  2.50it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  6.89it/s]\n",
            "                   all          3          3      0.753          1      0.995      0.641\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      34/39      9.58G    0.04079    0.01381          0          3        640: 100% 2/2 [00:01<00:00,  1.92it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  3.42it/s]\n",
            "                   all          3          3      0.936          1      0.995      0.653\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      35/39      9.58G    0.03512     0.0171          0          6        640: 100% 2/2 [00:00<00:00,  2.16it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  7.34it/s]\n",
            "                   all          3          3      0.759          1      0.995      0.653\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      36/39      9.58G    0.03406    0.01679          0          5        640: 100% 2/2 [00:00<00:00,  2.39it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  7.91it/s]\n",
            "                   all          3          3      0.759          1      0.995      0.653\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      37/39      9.58G    0.06439    0.01722          0          9        640: 100% 2/2 [00:00<00:00,  2.35it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  4.86it/s]\n",
            "                   all          3          3      0.919          1      0.995      0.653\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      38/39      9.58G    0.03286    0.01981          0          9        640: 100% 2/2 [00:01<00:00,  1.88it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  4.42it/s]\n",
            "                   all          3          3       0.91          1      0.995      0.653\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      39/39      9.58G    0.03221    0.01529          0          5        640: 100% 2/2 [00:00<00:00,  2.49it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  6.68it/s]\n",
            "                   all          3          3       0.91          1      0.995      0.653\n",
            "\n",
            "40 epochs completed in 0.068 hours.\n",
            "Optimizer stripped from yolov5/runs/train/exp2/weights/last.pt, 92.8MB\n",
            "Optimizer stripped from yolov5/runs/train/exp2/weights/best.pt, 92.8MB\n",
            "\n",
            "Validating yolov5/runs/train/exp2/weights/best.pt...\n",
            "Fusing layers... \n",
            "Model summary: 267 layers, 46108278 parameters, 0 gradients, 107.6 GFLOPs\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  5.30it/s]\n",
            "                   all          3          3     0.0142          1      0.995      0.697\n",
            "Results saved to \u001b[1myolov5/runs/train/exp2\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "! python yolov5/train.py --data trator.yaml --weights yolov5l.pt --img 640 --epochs 40"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aAemn27tbqNm"
      },
      "source": [
        "Quando terminar de executar, ele irÃ¡ mostrar o caminho de onde ficaram os resultados, geralmente: `yolov5/runs/train/exp[...]`\n",
        "\n",
        "Dentro dessa pasta, vocÃª consegue ver vÃ¡rias informaÃ§Ãµes sobre o treinamento, como os pesos, os grÃ¡ficos de perda, etc.\n",
        "\n",
        "Copie o caminho do arquivo `best.pt` dentro da pasta `weights` para podermos usar posteriormente.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ErPTgpIKbqNm"
      },
      "source": [
        "### Testando o modelo\n",
        "\n",
        "Vamos rodar o nosso modelo para ver como ele se comporta.\n",
        "\n",
        "Primeiro, crie uma pasta chamada `tests` e coloque dentro imagens que vocÃª deseja testar, de preferÃªncia imagens que nÃ£o foram usadas para treinar o modelo.\n",
        "\n",
        "Com as imagens na pasta, rode o cÃ³digo abaixo para testar o modelo:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rYQmIPDhbqNm"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import subprocess\n",
        "\n",
        "def get_latest_train_run_folder():\n",
        "    subfolders = [f.path for f in os.scandir('yolov5/runs/train') if f.is_dir()]\n",
        "    latest_folder = max(subfolders, key=os.path.getctime, default=None)\n",
        "    return latest_folder\n",
        "\n",
        "latest_run = get_latest_train_run_folder()\n",
        "\n",
        "# COMANDO\n",
        "\n",
        "result = subprocess.run(f'python yolov5/detect.py --weights {latest_run}/weights/best.pt --img 640 --source tests/ --data yolov5/data/trator.yaml', shell=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IaTTEyMQbqNn"
      },
      "source": [
        "Na linha final, o YOLO mostra onde ficou salvo os resultados da seguinte maneira:\n",
        "\n",
        "`Results saved to yolov5/runs/detect/exp1` (O nÃºmero da pasta varia de acordo com o nÃºmero de vezes que o YOLO foi executado)\n",
        "\n",
        "Dentro dessa pasta ele gera uma imagem com a box de detecÃ§Ã£o para cada imagem de teste. Exemplo:\n",
        "\n",
        "![Imagem de teste com label gerada pelo YOLO](docs/readme/test.jpg)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fmR4CYGNbqNn"
      },
      "source": [
        "## ConexÃ£o com o ESP32-CAM\n",
        "\n",
        "Primeiro, rode o [cÃ³digo](https://docs.google.com/document/d/1AnM97ejIS-_6f1mqPYu6Kl_hdNWh-9GAqmaCRdsK8W0/edit) que disponibiliza as imagens do ESP32 no Arduino IDE. Copie o link que ele gera no monitor serial para usar posteriormente.\n",
        "\n",
        "Com o cÃ³digo rodando, faÃ§a as alteraÃ§Ãµes necessÃ¡rias no cÃ³digo abaixo (linhas 6 e 7) para que ele se conecte ao ESP32-CAM e reconheÃ§a as imagens que ele envia.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sFKd5QhabqNn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 565
        },
        "outputId": "1f15c46b-3a6a-4b86-810e-0d42cf0f51d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://github.com/ultralytics/yolov5/zipball/master\" to /root/.cache/torch/hub/master.zip\n",
            "YOLOv5 ðŸš€ 2023-10-16 Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Fusing layers... \n",
            "Model summary: 157 layers, 7012822 parameters, 0 gradients, 15.8 GFLOPs\n",
            "Adding AutoShape... \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "yolov5/runs/train/exp/weights/best.pt\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "URLError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTimeoutError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/usr/lib/python3.10/urllib/request.py\u001b[0m in \u001b[0;36mdo_open\u001b[0;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[1;32m   1347\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1348\u001b[0;31m                 h.request(req.get_method(), req.selector, req.data, headers,\n\u001b[0m\u001b[1;32m   1349\u001b[0m                           encode_chunked=req.has_header('Transfer-encoding'))\n",
            "\u001b[0;32m/usr/lib/python3.10/http/client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1282\u001b[0m         \u001b[0;34m\"\"\"Send a complete request to the server.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1283\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/http/client.py\u001b[0m in \u001b[0;36m_send_request\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1328\u001b[0m             \u001b[0mbody\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'body'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1329\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendheaders\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/http/client.py\u001b[0m in \u001b[0;36mendheaders\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1277\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mCannotSendHeader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1278\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_body\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/http/client.py\u001b[0m in \u001b[0;36m_send_output\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1037\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1038\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1039\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/http/client.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    975\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_open\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 976\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    977\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/http/client.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    941\u001b[0m         \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maudit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"http.client.connect\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m         self.sock = self._create_connection(\n\u001b[0m\u001b[1;32m    943\u001b[0m             (self.host,self.port), self.timeout, self.source_address)\n",
            "\u001b[0;32m/usr/lib/python3.10/socket.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address)\u001b[0m\n\u001b[1;32m    844\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 845\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    846\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/socket.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address)\u001b[0m\n\u001b[1;32m    832\u001b[0m                 \u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_address\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m             \u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msa\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m             \u001b[0;31m# Break explicitly a reference cycle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTimeoutError\u001b[0m: [Errno 110] Connection timed out",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mURLError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-df48865816b9>\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mimg_resp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimage_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mimgnp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytearray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_resp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgnp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/urllib/request.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0mopener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minstall_opener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/urllib/request.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m         \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maudit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'urllib.Request'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 519\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    520\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m         \u001b[0;31m# post-process response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/urllib/request.py\u001b[0m in \u001b[0;36m_open\u001b[0;34m(self, req, data)\u001b[0m\n\u001b[1;32m    534\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m         \u001b[0mprotocol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 536\u001b[0;31m         result = self._call_chain(self.handle_open, protocol, protocol +\n\u001b[0m\u001b[1;32m    537\u001b[0m                                   '_open', req)\n\u001b[1;32m    538\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/urllib/request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhandler\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhandlers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 496\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    497\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/urllib/request.py\u001b[0m in \u001b[0;36mhttp_open\u001b[0;34m(self, req)\u001b[0m\n\u001b[1;32m   1375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1376\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhttp_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1377\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHTTPConnection\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1379\u001b[0m     \u001b[0mhttp_request\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAbstractHTTPHandler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_request_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/urllib/request.py\u001b[0m in \u001b[0;36mdo_open\u001b[0;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[1;32m   1349\u001b[0m                           encode_chunked=req.has_header('Transfer-encoding'))\n\u001b[1;32m   1350\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# timeout error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1351\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mURLError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1352\u001b[0m             \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1353\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mURLError\u001b[0m: <urlopen error [Errno 110] Connection timed out>"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import torch\n",
        "import numpy as np\n",
        "import urllib\n",
        "\n",
        "path = f'yolov5/runs/train/exp/weights/best.pt' # (OPCIONAL) TROQUE PELO CAMINHO DO SEU PESO CASO QUEIRA (best.pt que foi gerado no treinamento) ex: yolov5/runs/train/exp9/weights/best.pt\n",
        "image_url = 'http://192.168.43.201/cam-lo.jpg' # TROQUE PELO LINK GERADO NO MONITOR SERIAL\n",
        "\n",
        "model = torch.hub.load('ultralytics/yolov5', 'custom', path, force_reload=True)\n",
        "\n",
        "print(path)\n",
        "\n",
        "while True:\n",
        "    img_resp=urllib.request.urlopen(url=image_url)\n",
        "    imgnp=np.array(bytearray(img_resp.read()),dtype=np.uint8)\n",
        "    im = cv2.imdecode(imgnp,-1)\n",
        "\n",
        "    results = model(im)\n",
        "\n",
        "    print(results)\n",
        "\n",
        "    frame = np.squeeze(results.render())\n",
        "\n",
        "    cv2.imshow('Deteccao', frame)\n",
        "\n",
        "    key=cv2.waitKey(5)\n",
        "\n",
        "    if key==ord('q'):\n",
        "        break\n",
        "\n",
        "cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mCxbK93hbqNp"
      },
      "source": [
        "Ao rodar o cÃ³digo, deverÃ¡ abrir uma janela mostrando a camera do ESP-32. Aponte a camera para um alimento que vocÃª treinou e veja o resultado.\n",
        "\n",
        "![Resultado](docs/readme/esp32.png)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Teste de Webcam"
      ],
      "metadata": {
        "id": "Yg32EfEjWr2i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "path = 'yolov5/runs/train/exp/weights/best.pt'  # (OPCIONAL) TROQUE PELO CAMINHO DO SEU PESO CASO QUEIRA (best.pt que foi gerado no treinamento) ex: yolov5/runs/train/exp9/weights/best.pt\n",
        "\n",
        "# Abra a cÃ¢mera padrÃ£o (0 para a primeira cÃ¢mera)\n",
        "cap = cv2.VideoCapture(0)\n",
        "\n",
        "model = torch.hub.load('ultralytics/yolov5', 'custom', path, force_reload=True)\n",
        "\n",
        "while True:\n",
        "    # Captura um quadro da webcam\n",
        "    ret, frame = cap.read()\n",
        "\n",
        "    results = model(frame)\n",
        "\n",
        "    frame = np.squeeze(results.render())\n",
        "\n",
        "    cv2.imshow('DetecÃ§Ã£o', frame)\n",
        "\n",
        "    key = cv2.waitKey(1)\n",
        "\n",
        "    if key == ord('q'):\n",
        "        break\n",
        "\n",
        "# Libera a captura da cÃ¢mera e fecha a janela\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()\n"
      ],
      "metadata": {
        "id": "jX-j6M4CViP1"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}